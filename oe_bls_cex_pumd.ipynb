{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6761da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2018 diary\n",
      "Reading 2018 intrvw\n",
      "Reading the Hierarchical Groupings\n",
      "Reading the Dictionary\n",
      "Narrowing metadata to 2018\n",
      "Processing PUMD for 2018\n",
      "Processing flag fields\n",
      "     AGE_REF flagged by AGE_REF_\n",
      "     AGE2 flagged by AGE2_\n",
      "     CHILDAGE flagged by CHIL_AGE\n",
      "     CUTENURE flagged by CUTE_URE\n",
      "     EARNCOMP flagged by EARN_OMP\n",
      "     EDUC_REF flagged by EDUC0REF\n",
      "     EDUCA2 flagged by EDUCA2_\n",
      "     FAM_SIZE flagged by FAM__IZE\n",
      "     FAM_TYPE flagged by FAM__YPE\n",
      "     FJSSDEDM flagged by FJSS_EDM\n",
      "     FJSSDEDX flagged by FJSS_EDX\n",
      "     FS_MTHI flagged by FS_MTHI_\n",
      "     FSMPFRMX flagged by FSMP_RMX\n",
      "     FSMPFRXM flagged by FSMP_RXM\n",
      "     HH_CU_Q flagged by HH_CU_Q_\n",
      "     HHID flagged by HHID_\n",
      "     HORREF1 flagged by HORREF1_\n",
      "     HORREF2 flagged by HORREF2_\n",
      "     INC_RANK flagged by INC__ANK\n",
      "     INC_RNKM flagged by INC__NKM\n",
      "     INTRDVB flagged by INTRDVB_\n",
      "     INTRDVBX flagged by INTR_VBX\n",
      "     INTRDVX flagged by INTRDVX_\n",
      "     INTRDVXM flagged by INTR_VXM\n",
      "     JFS_AMT flagged by JFS_AMT_\n",
      "     MARITAL1 flagged by MARI_AL1\n",
      "     NETRENTB flagged by NETR_NTB\n",
      "     NETRENTM flagged by NETR_NTM\n",
      "     NETRENTX flagged by NETR_NTX\n",
      "     NETRNTBX flagged by NETR_TBX\n",
      "     NO_EARNR flagged by NO_E_RNR\n",
      "     OTHREGB flagged by OTHREGB_\n",
      "     OTHREGBX flagged by OTHR_GBX\n",
      "     OTHREGX flagged by OTHREGX_\n",
      "     OTHREGXM flagged by OTHR_GXM\n",
      "     PERSLT18 flagged by PERS_T18\n",
      "     PERSOT64 flagged by PERS_T64\n",
      "     RACE2 flagged by RACE2_\n",
      "     REF_RACE flagged by REF__ACE\n",
      "     RETSRVBX flagged by RETS_VBX\n",
      "     RETSURVB flagged by RETS_RVB\n",
      "     RETSURVM flagged by RETS_RVM\n",
      "     RETSURVX flagged by RETS_RVX\n",
      "     ROYESTB flagged by ROYESTB_\n",
      "     ROYESTBX flagged by ROYE_TBX\n",
      "     ROYESTX flagged by ROYESTX_\n",
      "     ROYESTXM flagged by ROYE_TXM\n",
      "     SEX_REF flagged by SEX_REF_\n",
      "     SEX2 flagged by SEX2_\n",
      "     VEHQ flagged by VEHQ_\n",
      "Writing to 2018 blockgroupspending file\n",
      "2018 (39861, 252)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "# oe_bls_cex_pumd\n",
    "## Overview\n",
    "---\n",
    "\n",
    "The Consumer Expenditure Survey represents national estimates based upon two original\n",
    "data collections: a Quarterly Interview Survey (Interview) and a Diary Survey (Diary).\n",
    "Ensuring confidentiality prohibits publication of all, identifiable data inputs.\n",
    "However, the BLS shares a sizeable sample of these sources, anonymized, called Public \n",
    "Use Microdata (PUMD).\n",
    "\n",
    "## Concepts & Glossary\n",
    "\n",
    "The Interview data has quarterly observations on each CU, while the Diary data is \n",
    "collected online bi-weekly.  So the PUMD datasets include a NEWID key that is the CU\n",
    "identifier (CUID) suffixed by the observation. For interview data, the last digit \n",
    "ranges quarters (1,2,3,4) and for diary entries ranges biweek (1,2).\n",
    "\n",
    "The PUMD includes a dimension of population density. First, CUs are split into Urban\n",
    "vs Outside Urban. Urban CUs are then split into includes a categorical variable called\n",
    "**popsize** or \"Population Size Area\" (PSA) which yields:\n",
    "- Outside urban area\n",
    "- All urban consumer units\n",
    "- Less than 100,000\n",
    "- 100,000 to 249,999\n",
    "- 250,000 to 999,999\n",
    "- 1,000,000 to 2,499,999\n",
    "- 2,500,000 to 4,999,999\n",
    "- 5,000,000 and more\n",
    "\n",
    "The PUMD is published as sets of SAS, STAT or csv files.\n",
    "This processing uses the csv file format.\n",
    "\n",
    "The lowest level of detail collected in the PUMD is assigned a Universal\n",
    "Classification Code (UCC), a six digit string left padded with zeros. The\n",
    "BLS also uses these categories of spending for its Consumer Price Inflation (CPI)\n",
    "publication.\n",
    "\n",
    "For the PUMD, the UCC details are aggregated in to tree of subtotalling variables,\n",
    "in a stucture called the hierarchical grouping (HG). The HG has three forms for the \n",
    "Interview, Diary and 'Integrated' view of the PUMD data. The lowest level nodes on the\n",
    "HG are UCCs themselves. For example, the UCCs for cookies ('020510') and crackers \n",
    "('20610') are subtotaled to the variable \"CRAKCOOK\". \n",
    "\n",
    "At the highest level, the HG sums into four sections:\n",
    "- Consumer unit characteristics like number of people, age of the reference person\n",
    "- Demographics like race, ethnicity, education\n",
    "- Incomes and Taxes\n",
    "- Spending (finally) also called Average Annual Expenditures\n",
    "This last, largest group of variables has its first level of detail such as Food,\n",
    "Housing, Transportation and Health care.\n",
    "\n",
    "The PUMD data is distributed by year, in quarterly files that have one of these formats:\n",
    "  Diary Files\n",
    "    FMLD - characteristics, income, weights, and summary level expenditures for the CU.\n",
    "    MEMD - characteristics and income for each member in the CU.\n",
    "    EXPD - a detailed weekly expenditure file categorized by UCC.\n",
    "    DTBD - a detailed annual income file categorized by UCC.\n",
    "    DTID - a Consumer Unit imputed income file categorized by UCC.\n",
    "  Interview Files\n",
    "    FMLI - characteristics, income, weights, and summary level expenditures for the CU.\n",
    "    MEMI - characteristics and income for each member in the CU.\n",
    "    MTBI - a detailed monthly expenditure file categorized by UCC.\n",
    "    ITBI - a Consumer Unit monthly income file categorized by UCC.\n",
    "    ITII - a Consumer Unit monthly imputed income file categorized by UCC.4\n",
    "    NTAXI - a file with federal and state tax information for each tax unit in the CU.5\n",
    "\n",
    "While these are many, the BLS shares some programming that focuses on just four. The\n",
    "'family' data are keyed by Consumer Unit (CU) from each of the interview and diary sets\n",
    "(FMLI & FMLD).  The UCC level spending details are found in (EXPD & MTBI)\n",
    "\n",
    "---\n",
    "## Bugs & Issues\n",
    "- One year has two columns were lowercase\n",
    "- In 2018, vars were renamed\n",
    "\n",
    "\n",
    "---\n",
    "## Citations\n",
    "Public Use Microdata (PUMD) https://www.bls.gov/cex/pumd_data.htm\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def oe_bls_cex_pumd_download(years, pumddir = './pumd/', cexurl='https://www.bls.gov/cex/'):\n",
    "    \"\"\"\n",
    "    This function downloads the files, dictionaries and hierarchical groupings of in\n",
    "    Bureau of Labor Statistics (BLS), Consumer Expenditure Survey's (CEX) Public Use \n",
    "    Microsample Data (PUMD).\n",
    "        \n",
    "    :param  years:    a list of 4 digit years that are strings like ['2018','2019','2020'] \n",
    "    :param  pumddir:  a string with the path destination of the download & unzipped files \n",
    "    :param  cexurl:   the root URL for the Consumer Expenditure Survey\n",
    "\n",
    "    :return None   The function either succeeds or fails\n",
    "    \"\"\"\n",
    "    \n",
    "    # Avoid conflicts with any previously downloaded\n",
    "    if os.path.exists(pumddir):\n",
    "        print(\"Destination directory '\"+pumddir+\"already exists.\")\n",
    "        print(\"Please remove it or select a new destination directory.\")\n",
    "        raise\n",
    "    else:\n",
    "        os.mkdir(pumddir)\n",
    "\n",
    "    # Download and reformat the HGs as a dictionary of dataframes\n",
    "    for yr in years:\n",
    "        for fn in ('diary','intrvw'):\n",
    "            # download\n",
    "            print('Downloading',yr,fn)\n",
    "            wget.download(cexurl+'pumd/data/comma/'+fn+yr[2:]+'.zip',\n",
    "                          out=pumddir,\n",
    "                          bar=None)\n",
    "            # unzip\n",
    "            with zipfile.ZipFile(pumddir+fn+yr[2:]+'.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(pumddir)\n",
    "            \n",
    "    # also need the HG file.  It is a zip of all years.\n",
    "    print('Downloading Hierarchical Grouping file')\n",
    "    wget.download(cexurl+'pumd/stubs.zip', \n",
    "                  out=pumddir,\n",
    "                  bar=None)\n",
    "    with zipfile.ZipFile(pumddir+'stubs.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(pumddir)\n",
    "\n",
    "    # Get the PUMD dictionary\n",
    "    print('Getting the PUMD dictionary')\n",
    "    wget.download(cexurl+'pumd/ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                  out=pumddir,\n",
    "                  bar=None)\n",
    "\n",
    "    return None\n",
    "\n",
    "def oe_bls_cex_pumd_open_files(years, pumddir = './pumd/'):\n",
    "    \"\"\"\n",
    "    This function reads the PUMD data files of the dataset into python data structures. \n",
    "\n",
    "        \n",
    "    :param  years: a list of 4 digit years that are strings     ['2018','2019','2020'] \n",
    "    :param  UCCs: a list of UCCs, six digit as strings     ['123456','234567','345678']\n",
    "\n",
    "    pumdfiles: a dictionary, by year, with the file based dataframes\n",
    "    hg: the Hierarchical Grouping table with linenum, level, title, survey, factor.\n",
    "    vardict: provides a dictionary of the variables (not UCCs) in the PUMD\n",
    "    codedict: provides a table with a description for each coded value in the PUMD\n",
    "\n",
    "    :return  pumdfiles, hg, vardict, codedict\n",
    "    \"\"\"\n",
    "    \n",
    "    filetypes = ['dtbd','dtid','expd','fmld','memd','fmli','itbi','itii','memi','mtbi','ntax']\n",
    "\n",
    "    filereads = {}\n",
    "    for t in filetypes:\n",
    "        filereads[t] = []\n",
    "        \n",
    "    pumd = {}\n",
    "    \n",
    "    for yr in years:\n",
    "        pumd[yr] = {}\n",
    "        for fn in ('diary','intrvw'):\n",
    "            print(\"Reading\",yr,fn)\n",
    "            # Sometimes the intrv folder is in another subdir:  intrvw17/intrvw17/*.csv eg \n",
    "            if ((fn == 'intrvw') & (os.path.exists(pumddir+fn+yr[-2:]+ \"\\\\\"+fn+yr[-2:]+\"\\\\\"))):\n",
    "                folder = fn+yr[-2:]+ \"\\\\\"+fn+yr[-2:]+\"\\\\\"\n",
    "            else:\n",
    "                folder = fn+yr[-2:]+ \"\\\\\"\n",
    "            for f in os.listdir(pumddir+folder):\n",
    "                ftype = f[0:4]\n",
    "                if ftype in filetypes:\n",
    "                    fdf = pd.read_csv(pumddir+folder+f, dtype=object)\n",
    "                    fdf.columns = [c.upper() for c in fdf.columns]\n",
    "                    fdf[\"filename\"] = f\n",
    "                    fdf[\"year\"] = yr\n",
    "                    filereads[ftype].append(fdf)\n",
    "\n",
    "        for t in filetypes:\n",
    "            pumd[yr][t] = pd.concat(filereads[t])   \n",
    "    \n",
    "    print('Reading the Hierarchical Groupings')\n",
    "    # I'll use the Integrated HG.  Its mostly a superset of Interview & Diary HG less a dozen each\n",
    "    hg = {}\n",
    "    hgdtypes = {\"linenum\":int, \"level\":str, \"title\":str, \"ucc\":str, \"survey\":str, \"factor\":str, \"group\":str}\n",
    "    for yr in years:\n",
    "        h = pd.read_fwf(pumddir+'stubs\\\\CE-HG-Integ-'+yr+'.txt', index_col=False,\n",
    "        names = [\"linenum\", \"level\",  \"title\",  \"ucc\",     \"survey\",  \"factor\", \"group\"],\n",
    "        colspecs = [(0, 3),  (3, 6),  (6, 69),  (69, 75),  (82, 85),  (85, 88), (88,95)],\n",
    "        dtype=hgdtypes)    \n",
    "        # Rows with linenum == 2 are just title text that wrapped from the previous row.\n",
    "        for i,r in h.iterrows():\n",
    "            if r.linenum == 2:\n",
    "                h.at[i-1,'title'] = h.at[i-1,'title']+' '+r.title\n",
    "        hg[yr] = h[h.linenum == 1]\n",
    "     \n",
    "    print('Reading the Dictionary')\n",
    "    # The sheet names can varyin capitalization and include spaces\n",
    "    xl = pd.ExcelFile(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx')\n",
    "    varsheet =  [c for c in xl.sheet_names if 'vari' in c.lower()][0]\n",
    "    codesheet = [c for c in xl.sheet_names if 'code' in c.lower()][0]\n",
    "\n",
    "    vardict =   pd.read_excel(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                              sheet_name = varsheet)\n",
    "    codedict =  pd.read_excel(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                              sheet_name = codesheet)\n",
    "\n",
    "    # filter the vardict sheet to only those where \n",
    "    #     you year of interest is > First Year > First Quart and < Last Year <Last Quarter\n",
    "    \n",
    "    return  pumd, hg, vardict, codedict\n",
    "\n",
    "def oe_bls_cex_pumd_interpret_data(pumd, vardict, year, sumrules):\n",
    "    \"\"\"\n",
    "    This function applies adjustments, logical rules and corrections to this source\n",
    "    are applied by the related oe_bls_cex_pumd_read function.to PUMD data structures. \n",
    "\n",
    "    :param  years: a list of 4 digit years that are strings     ['2018','2019','2020'] \n",
    "    :param  UCCs: a list of UCCs, six digit as strings     ['123456','234567','345678']\n",
    "\n",
    "    pumdfiles: a dictionary, by year, with the file based dataframes\n",
    "    hg: the Hierarchical Grouping table with linenum, level, title, survey, factor.\n",
    "    vardict: provides a dictionary of the variables (not UCCs) in the PUMD\n",
    "    sumrules: a dataframe of each summary variable name, summary level and list of children \n",
    "            columns to sum\n",
    "\n",
    "    The processing logic replicates what the BLS' own SAS (& R) program does!\n",
    "    See:    https://www.bls.gov/cex/pumd-getting-started-guide.htm\n",
    "            https://www.bls.gov/cex/pumd/sas-ucc.zip\n",
    "            https://www.bls.gov/cex/pumd/r-ucc.zip\n",
    "            \n",
    "    This is also helpful \n",
    "            https://www.bls.gov/cex/pumd_doc.htm\n",
    "            https://www.bls.gov/cex/csxintvw.pdf\n",
    "\n",
    "    :return family:  a dataframe keyed by CU (NEWID) \n",
    "    :return expend:  a dataframe keyed by CU & UCC \n",
    "    :return pubfile: a join between family, expend \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Processing PUMD for\", year)\n",
    "\n",
    "    # Get family dataframes for Interview and Diary\n",
    "    fmli = pumd[year]['fmli']\n",
    "    fmld = pumd[year]['fmld']\n",
    "    # Get member level dataframes\n",
    "    mtbi = pumd[year]['mtbi']\n",
    "    expd = pumd[year]['expd']\n",
    "\n",
    "    # column name lists\n",
    "    wtrep = [(\"WTREP\"+str(i+1).zfill(2)) for i in range(44)]+[\"FINLWT21\"] ## WTREP01-REPWT444 and FINL\n",
    "    repwt = [(\"REPWT\"+str(i+1)) for i in range(45)]  # REPWT1-REPWT45\n",
    "    rcost = [(\"RCOST\"+str(i+1)) for i in range(45)]  # RCOST1-RCOST45\n",
    "\n",
    "    # Process Family\n",
    "\n",
    "    fmli[\"source\"] = 'I'\n",
    "\n",
    "    def mo_scope(row):\n",
    "        if   (row[\"QINTRVMO\"] in ['01','02','03']) & (row[\"QINTRVYR\"]==year):\n",
    "            return (int(row[\"QINTRVMO\"]) - 1)\n",
    "        elif (row[\"QINTRVMO\"] in ['01','02','03']) & (row[\"QINTRVYR\"]==str(int(year)+1)):\n",
    "            return (4 - int(row[\"QINTRVMO\"]))\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    fmli['mo_scope'] = fmli.apply(mo_scope, axis=1)\n",
    "\n",
    "    for i in range(45):\n",
    "        fmli[wtrep[i]] = fmli[wtrep[i]].astype(float).fillna(0)\n",
    "        fmli[repwt[i]] = (fmli[wtrep[i]] * fmli[\"mo_scope\"]) / 12\n",
    "\n",
    "    fmld[\"source\"] = \"D\"\n",
    "    fmld[\"mo_scope\"] = 3\n",
    "    for i in range(45):\n",
    "        fmld[wtrep[i]] = fmld[wtrep[i]].astype(float).fillna(0)    \n",
    "        fmld[repwt[i]] = (fmld[wtrep[i]] * fmld[\"mo_scope\"]) / 12\n",
    "\n",
    "    fmli = fmli.reset_index()\n",
    "    fmld = fmld.reset_index()\n",
    "    fmlcols = ([c for c in fmli.columns if c in fmld.columns]) # 272 columns\n",
    "    family = pd.concat([fmli[fmlcols],fmld[fmlcols]], axis=0)\n",
    "\n",
    "    # Process flag fields   _ values of A,B,C are NAs\n",
    "    print(\"Processing flag fields\")\n",
    "    def flag_NAs(row,flagged,flagcol):\n",
    "        if row[flagcol] in [\"A\",\"B\",\"C\"]:\n",
    "            return np.NaN\n",
    "        else:\n",
    "            return row[flagged]\n",
    "        return None\n",
    "\n",
    "    flags = {}\n",
    "    flag_candidates = vardict[[\"Variable Name\",\"Flag name\"]][~vardict[\"Flag name\"].isna()].drop_duplicates()\n",
    "    for i,r in flag_candidates.iterrows():\n",
    "        if (r[\"Variable Name\"] in family.columns) & (r[\"Flag name\"] in family.columns):\n",
    "            flags[r[\"Variable Name\"]] = r[\"Flag name\"]\n",
    "\n",
    "    for col in flags.keys():\n",
    "        print(\"    \",col,\"flagged by\",flags[col])\n",
    "        family[col[:-1]] = family.apply(lambda row: flag_NAs(row,col,flags[col]), axis=1)\n",
    "\n",
    "    family.drop([c for c in flags.values()], axis=1, inplace=True)\n",
    "    fmlcols = family.columns  # reset this list\n",
    "\n",
    "    # Process Expend\n",
    "\n",
    "    mtbi[\"source\"] = \"I\"\n",
    "    mtbi = mtbi[(mtbi[\"REF_YR\"] == year) & (mtbi[\"PUBFLAG\"] == \"2\")]\n",
    "\n",
    "    expd[\"source\"] = \"D\"\n",
    "    expd[\"COST\"] = pd.to_numeric(expd[\"COST\"], errors='coerce')\n",
    "    expd[\"COST\"] = expd[\"COST\"].astype(float).fillna(0) * 13\n",
    "    expd = expd[expd[\"PUB_FLAG\"] == \"2\"]\n",
    "\n",
    "    expcols =['NEWID','source','UCC','COST'] #,'REF_YR'\n",
    "    expend = pd.concat([mtbi[expcols],expd[expcols]], axis=0)\n",
    "\n",
    "    pubfile = pd.merge(family, expend, on='NEWID', how='inner')\n",
    "    pubfile[\"COST\"] = pubfile[\"COST\"].astype(float).fillna(0)\n",
    "    for i in range(45):\n",
    "        pubfile[rcost[i]] = pubfile[wtrep[i]] * pubfile[\"COST\"]\n",
    "        \n",
    "    #\n",
    "    # TBD: summarize the pubfile, and apply the sumrules\n",
    "    #\n",
    "    \n",
    "    # 1. Start with a df that has CUID/NEWID, COST and UCC columns\n",
    "    # 2. Pivot this df so there's a column for each UCC value\n",
    "        # costs = df.pivot(index='NEWID', columns='UCC', values='COST')\n",
    "    # 3. Ensure that all the expected UCC columns are present\n",
    "    #   # for all the UCC variables, if the cost df is missing that var, costs[missingUCC] = 0\n",
    "    # 4. March from the lowest level upward\n",
    "        # for level in [9,8,7,6,5,4,3,2]:\n",
    "    #   costs[sumvar] = costs[sumrulescolumns].sum(axis=1)\n",
    "        \n",
    "    return pubfile, family, expend, fmli, fmld, mtbi, expd\n",
    "\n",
    "def oe_bls_cex_pumd_interpret_meta(hg,vd,cd,year):\n",
    "\n",
    "    print(\"Narrowing metadata to\", year)\n",
    "    \n",
    "    # Interpret the Hierarchical Grouping\n",
    "    h = hg[year]\n",
    "    \n",
    "    # Generate the summarization rules from HG\n",
    "    h[\"level\"] = h[\"level\"].astype(int)\n",
    "    sumdict = {}\n",
    "    sumrules = {}\n",
    "    for level in [9,8,7,6,5,4,3,2]:\n",
    "        for i,g in h[h.level.isin([level, level-1])].iterrows():        \n",
    "            if g.level == level-1:\n",
    "                rule = g.ucc\n",
    "                sumdict[rule] = level-1\n",
    "                sumrules[rule] = []\n",
    "            else:\n",
    "                sumrules[rule].append(g.ucc)\n",
    "\n",
    "    emptyrules = [r for r in sumrules.keys() if len(sumrules[r]) == 0]\n",
    "    for rule in emptyrules:\n",
    "        sumrules.pop(rule)\n",
    "        sumdict.pop(rule)\n",
    "\n",
    "    # Test the rules\n",
    "    for rule in sumrules.keys():\n",
    "        if (len(sumrules[rule]) > 0) & (rule.isnumeric()):\n",
    "            print('invalid rule',rule,': members but numeric')\n",
    "        if (len(sumrules[rule]) == 0) & (not rule.isnumeric()):\n",
    "            print('invalid rule',rule,': no members but not numeric')\n",
    "    # the rule level is needed so they can be applied bottom up\n",
    "    r = pd.DataFrame.from_dict({'name':  list(sumdict.keys()),\n",
    "                                'level': [sumdict[r] for r in sumdict.keys()],\n",
    "                                'rule':  [sumrules[r] for r in sumdict.keys()]})    \n",
    "    \n",
    "    # Interpret the Var Dictionary\n",
    "    vd[\"Last year\"] = vd[\"Last year\"].fillna(datetime.now().year)\n",
    "    v = vd[(int(year) >= vd[\"First year\"] ) & (int(year) <= vd[\"Last year\"] )]\n",
    "    \n",
    "    # Interpret the Code Dictionary\n",
    "    cd[\"Last year\"] = cd[\"Last year\"].fillna(datetime.now().year)\n",
    "    c = cd[(int(year) >= cd[\"First year\"] ) & (int(year) <= cd[\"Last year\"] )]\n",
    "    \n",
    "    return h,r,v,c\n",
    "\n",
    "\n",
    "def oe_bls_cex_pumd_write(df, year):\n",
    "    \"\"\"\n",
    "    This function writes a final dataframe to file.\n",
    "    \"\"\"\n",
    "    print(\"Writing to \"+year+\" blockgroupspending file\")\n",
    "    df.to_csv(year+'blockgroupspending.csv', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Capitalized variables are globals or multi-year storage\n",
    "    # Lowercase variables are those for a given working year\n",
    "    \n",
    "    CEXURL = 'https://www.bls.gov/cex/'\n",
    "    PUMDDIR = \"D:\\\\Open Environments\\\\data\\\\bls\\\\cex\\\\pumd\\\\\"\n",
    "    YEARS = ['2016','2017','2018','2019','2020']\n",
    "    \n",
    "    oe_bls_cex_pumd_download(YEARS, pumddir = PUMDDIR, cexurl=CEXURL)\n",
    "    \n",
    "    PUMD, HG, VARDICT, CODEDICT = oe_bls_cex_pumd_open_files(YEARS, pumddir = PUMDDIR)\n",
    "    \n",
    "    for yr in YEARS: \n",
    "        hg, sumrules, vardict, codedict    = oe_bls_cex_pumd_interpret_meta(HG,VARDICT,CODEDICT,yr)\n",
    "        pubfile, family, expend, fmli, fmld, mtbi, expd  = \\\n",
    "            oe_bls_cex_pumd_interpret_data(PUMD,VARDICT,yr,sumrules)\n",
    "        oe_bls_cex_pumd_write(family,yr)\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de1b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113aa728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6835d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc7703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d72a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

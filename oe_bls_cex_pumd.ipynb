{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6761da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018 diary\n",
      "Downloading 2018 intrvw\n",
      "Downloading Hierarchical Grouping file\n",
      "Getting the PUMD dictionary\n",
      "Reading 2018 diary\n",
      "Reading 2018 intrvw\n",
      "Reading the Hierarchical Groupings\n",
      "Reading the Dictionary\n",
      "Narrowing metadata to 2018\n",
      "Processing PUMD for 2018\n",
      "Processing flags for FMLI\n",
      "Flag candidates found (190, 2)\n",
      "Applying flags 188\n",
      "     AGE_REF flagged by AGE_REF_\n",
      "     AGE2 flagged by AGE2_\n",
      "     APTMENT flagged by APTMENT_\n",
      "     AS_COMP1 flagged by AS_C_MP1\n",
      "     AS_COMP2 flagged by AS_C_MP2\n",
      "     AS_COMP3 flagged by AS_C_MP3\n",
      "     AS_COMP4 flagged by AS_C_MP4\n",
      "     AS_COMP5 flagged by AS_C_MP5\n",
      "     BATHRMQ flagged by BATHRMQ_\n",
      "     BEDROOMQ flagged by BEDR_OMQ\n",
      "     BUILDING flagged by BUIL_ING\n",
      "     BUILT flagged by BUILT_\n",
      "     BUSCREEN flagged by BUSC_EEN\n",
      "     CHILDAGE flagged by CHIL_AGE\n",
      "     CNTRALAC flagged by CNTR_LAC\n",
      "     CREDFINX flagged by CRED_INX\n",
      "     CREDITB flagged by CREDITB_\n",
      "     CREDITBX flagged by CRED_TBX\n",
      "     CREDITX flagged by CREDITX_\n",
      "     CREDTYRX flagged by CRED_YRX\n",
      "     CREDYR flagged by CREDYR_\n",
      "     CREDYRB flagged by CREDYRB_\n",
      "     CREDYRBX flagged by CRED_RBX\n",
      "     CUTENURE flagged by CUTE_URE\n",
      "     DEFBENRP flagged by DEFB_NRP\n",
      "     DIRACC flagged by DIRACC_\n",
      "     EARNCOMP flagged by EARN_OMP\n",
      "     EDUC_REF flagged by EDUC0REF\n",
      "     EDUCA2 flagged by EDUCA2_\n",
      "     ERANKH flagged by ERANKH_\n",
      "     ERANKHM flagged by ERANKHM_\n",
      "     FAM_SIZE flagged by FAM__IZE\n",
      "     FAM_TYPE flagged by FAM__YPE\n",
      "     FFTAXOWE flagged by FFTA_OWE\n",
      "     FGOVRETM flagged by FGOV_ETM\n",
      "     FGOVRETX flagged by FGOV_ETX\n",
      "     FINATXEM flagged by FINAT_EM\n",
      "     FINCBTAX flagged by FINCBT_X\n",
      "     FINCBTXM flagged by FINCB_XM\n",
      "     FINDRETX flagged by FIND_ETX\n",
      "     FJSSDEDM flagged by FJSS_EDM\n",
      "     FJSSDEDX flagged by FJSS_EDX\n",
      "     FMLPYYRX flagged by FMLP_YRX\n",
      "     FPRIPENM flagged by FPRI_ENM\n",
      "     FPRIPENX flagged by FPRI_ENX\n",
      "     FRRDEDM flagged by FRRDEDM_\n",
      "     FRRDEDX flagged by FRRDEDX_\n",
      "     FRRETIRM flagged by FRRE_IRM\n",
      "     FRRETIRX flagged by FRRE_IRX\n",
      "     FS_MTHI flagged by FS_MTHI_\n",
      "     FSALARYM flagged by FSAL_RYM\n",
      "     FSALARYX flagged by FSAL_RYX\n",
      "     FSMPFRMX flagged by FSMP_RMX\n",
      "     FSMPFRXM flagged by FSMP_RXM\n",
      "     FSSIX flagged by FSSIX_\n",
      "     FSSIXM flagged by FSSIXM_\n",
      "     FSTAXOWE flagged by FSTA_OWE\n",
      "     HH_CU_Q flagged by HH_CU_Q_\n",
      "     HHID flagged by HHID_\n",
      "     HLFBATHQ flagged by HLFB_THQ\n",
      "     HORREF1 flagged by HORREF1_\n",
      "     HORREF2 flagged by HORREF2_\n",
      "     INC_HRS2 flagged by INC__RS2\n",
      "     INC_RANK flagged by INC__ANK\n",
      "     INC_RNKM flagged by INC__NKM\n",
      "     INCLASS2 flagged by INCL_SS2\n",
      "     INCNONW1 flagged by INCN_NW1\n",
      "     INCNONW2 flagged by INCN_NW2\n",
      "     INCOMEY1 flagged by INCO_EY1\n",
      "     INCOMEY2 flagged by INCO_EY2\n",
      "     INCWEEK1 flagged by INCW_EK1\n",
      "     INCWEEK2 flagged by INCW_EK2\n",
      "     INTRDVB flagged by INTRDVB_\n",
      "     INTRDVBX flagged by INTR_VBX\n",
      "     INTRDVX flagged by INTRDVX_\n",
      "     INTRDVXM flagged by INTR_VXM\n",
      "     IRA flagged by IRA_\n",
      "     IRAB flagged by IRAB_\n",
      "     IRABX flagged by IRABX_\n",
      "     IRAX flagged by IRAX_\n",
      "     IRAYR flagged by IRAYR_\n",
      "     IRAYRB flagged by IRAYRB_\n",
      "     IRAYRBX flagged by IRAYRBX_\n",
      "     IRAYRX flagged by IRAYRX_\n",
      "     JFS_AMT flagged by JFS_AMT_\n",
      "     LIQDYRBX flagged by LIQD_RBX\n",
      "     LIQUDYR flagged by LIQUDYR_\n",
      "     LIQUDYRB flagged by LIQU_YRB\n",
      "     LIQUDYRX flagged by LIQU_YRX\n",
      "     LIQUID flagged by LIQUID_\n",
      "     LIQUIDB flagged by LIQUIDB_\n",
      "     LIQUIDBX flagged by LIQU_DBX\n",
      "     LIQUIDX flagged by LIQUIDX_\n",
      "     LMPSUMBX flagged by LMPS_MBX\n",
      "     LUMPSUMB flagged by LUMP_UMB\n",
      "     LUMPSUMX flagged by LUMP_UMX\n",
      "     MARITAL1 flagged by MARI_AL1\n",
      "     MEALSPAY flagged by MEAL_PAY\n",
      "     MISCTAXX flagged by MISC_AXX\n",
      "     MLPAYWKX flagged by MLPA_WKX\n",
      "     MLPYQWKS flagged by MLPY_WKS\n",
      "     NETRENTB flagged by NETR_NTB\n",
      "     NETRENTM flagged by NETR_NTM\n",
      "     NETRENTX flagged by NETR_NTX\n",
      "     NETRNTBX flagged by NETR_TBX\n",
      "     NO_EARNR flagged by NO_E_RNR\n",
      "     NONINCMX flagged by NONI_CMX\n",
      "     NUM_AUTO flagged by NUM__UTO\n",
      "     NUM_TVAN flagged by NUM__VAN\n",
      "     OCCUCOD1 flagged by OCCU_OD1\n",
      "     OCCUCOD2 flagged by OCCU_OD2\n",
      "     OFSTPARK flagged by OFST_ARK\n",
      "     OTHASTB flagged by OTHASTB_\n",
      "     OTHASTBX flagged by OTHA_TBX\n",
      "     OTHASTX flagged by OTHASTX_\n",
      "     OTHFINX flagged by OTHFINX_\n",
      "     OTHLNYR flagged by OTHLNYR_\n",
      "     OTHLNYRB flagged by OTHL_YRB\n",
      "     OTHLNYRX flagged by OTHL_YRX\n",
      "     OTHLOAN flagged by OTHLOAN_\n",
      "     OTHLONB flagged by OTHLONB_\n",
      "     OTHLONBX flagged by OTHL_NBX\n",
      "     OTHLONX flagged by OTHLONX_\n",
      "     OTHLYRBX flagged by OTHL_RBX\n",
      "     OTHREGB flagged by OTHREGB_\n",
      "     OTHREGBX flagged by OTHR_GBX\n",
      "     OTHREGX flagged by OTHREGX_\n",
      "     OTHREGXM flagged by OTHR_GXM\n",
      "     OTHRINCB flagged by OTHR_NCB\n",
      "     OTHRINCM flagged by OTHR_NCM\n",
      "     OTHRINCX flagged by OTHR_NCX\n",
      "     OTHSTYR flagged by OTHSTYR_\n",
      "     OTHSTYRB flagged by OTHS_YRB\n",
      "     OTHSTYRX flagged by OTHS_YRX\n",
      "     OTHSYRBX flagged by OTHS_RBX\n",
      "     OTRINCBX flagged by OTRI_CBX\n",
      "     PERSLT18 flagged by PERS_T18\n",
      "     PERSOT64 flagged by PERS_T64\n",
      "     PORCH flagged by PORCH_\n",
      "     PRINEARN flagged by PRIN_ARN\n",
      "     PRINERNM flagged by PRIN_RNM\n",
      "     RACE2 flagged by RACE2_\n",
      "     REF_RACE flagged by REF__ACE\n",
      "     RENTEQVX flagged by RENT_QVX\n",
      "     RETSRVBX flagged by RETS_VBX\n",
      "     RETSURV flagged by RETSURV_\n",
      "     RETSURVB flagged by RETS_RVB\n",
      "     RETSURVM flagged by RETS_RVM\n",
      "     RETSURVX flagged by RETS_RVX\n",
      "     ROOMSQ flagged by ROOMSQ_\n",
      "     ROYESTB flagged by ROYESTB_\n",
      "     ROYESTBX flagged by ROYE_TBX\n",
      "     ROYESTX flagged by ROYESTX_\n",
      "     ROYESTXM flagged by ROYE_TXM\n",
      "     SEX_REF flagged by SEX_REF_\n",
      "     SEX2 flagged by SEX2_\n",
      "     SOLARPNL flagged by SOLA_PNL\n",
      "     ST_HOUS flagged by ST_HOUS_\n",
      "     STCKYRBX flagged by STCK_RBX\n",
      "     STDNTYR flagged by STDNTYR_\n",
      "     STDNTYRB flagged by STDN_YRB\n",
      "     STDNTYRX flagged by STDN_YRX\n",
      "     STDTYRBX flagged by STDT_RBX\n",
      "     STOCKB flagged by STOCKB_\n",
      "     STOCKBX flagged by STOCKBX_\n",
      "     STOCKX flagged by STOCKX_\n",
      "     STOCKYR flagged by STOCKYR_\n",
      "     STOCKYRB flagged by STOC_YRB\n",
      "     STOCKYRX flagged by STOC_YRX\n",
      "     STUDFINX flagged by STUD_INX\n",
      "     STUDNTB flagged by STUDNTB_\n",
      "     STUDNTBX flagged by STUD_TBX\n",
      "     STUDNTX flagged by STUDNTX_\n",
      "     SWIMPOOL flagged by SWIM_OOL\n",
      "     UNISTRQ flagged by UNISTRQ_\n",
      "     VEHQ flagged by VEHQ_\n",
      "     VEHQL flagged by VEHQL_\n",
      "     WELFAREM flagged by WELF_REM\n",
      "     WELFAREX flagged by WELF_REX\n",
      "     WELFREBX flagged by WELF_EBX\n",
      "     WHLFYR flagged by WHLFYR_\n",
      "     WHLFYRB flagged by WHLFYRB_\n",
      "     WHLFYRBX flagged by WHLF_RBX\n",
      "     WHLFYRX flagged by WHLFYRX_\n",
      "     WHOLIFB flagged by WHOLIFB_\n",
      "     WHOLIFBX flagged by WHOL_FBX\n",
      "     WHOLIFX flagged by WHOLIFX_\n",
      "     WINDOWAC flagged by WIND_WAC\n",
      "dropping flag gields 188\n",
      "Processing flags for FMLD\n",
      "Flag candidates found (101, 2)\n",
      "Applying flags 99\n",
      "     AGE_REF flagged by AGE_REF_\n",
      "     AGE2 flagged by AGE2_\n",
      "     CHILDAGE flagged by CHIL_AGE\n",
      "     CUTENURE flagged by CUTE_URE\n",
      "     DESCRIP flagged by DESCRIP_\n",
      "     EARNCOMP flagged by EARN_OMP\n",
      "     EDUC_REF flagged by EDUC0REF\n",
      "     EDUCA2 flagged by EDUCA2_\n",
      "     EMPLTYP1 flagged by EMPL_YP1\n",
      "     EMPLTYP2 flagged by EMPL_YP2\n",
      "     FAM_SIZE flagged by FAM__IZE\n",
      "     FAM_TYPE flagged by FAM__YPE\n",
      "     FGVX flagged by FGVX_\n",
      "     FGVXM flagged by FGVXM_\n",
      "     FINCBEFM flagged by FINC_EFM\n",
      "     FINCBEFX flagged by FINC_EFX\n",
      "     FIRAX flagged by FIRAX_\n",
      "     FJSSDEDM flagged by FJSS_EDM\n",
      "     FJSSDEDX flagged by FJSS_EDX\n",
      "     FPVTX flagged by FPVTX_\n",
      "     FPVTXM flagged by FPVTXM_\n",
      "     FREEMLX flagged by FREEMLX_\n",
      "     FRRX flagged by FRRX_\n",
      "     FRRXM flagged by FRRXM_\n",
      "     FS_AMTXM flagged by FS_A_TXM\n",
      "     FS_MTHI flagged by FS_MTHI_\n",
      "     FSMPFRMX flagged by FSMP_RMX\n",
      "     FSMPFRXM flagged by FSMP_RXM\n",
      "     FSS_RRX flagged by FSS_RRX_\n",
      "     FSS_RRXM flagged by FSS__RXM\n",
      "     FSUPPX flagged by FSUPPX_\n",
      "     FSUPPXM flagged by FSUPPXM_\n",
      "     FWAGEX flagged by FWAGEX_\n",
      "     FWAGEXM flagged by FWAGEXM_\n",
      "     HH_CU_Q flagged by HH_CU_Q_\n",
      "     HHID flagged by HHID_\n",
      "     HORREF1 flagged by HORREF1_\n",
      "     HORREF2 flagged by HORREF2_\n",
      "     HRSPRWK1 flagged by HRSP_WK1\n",
      "     HRSPRWK2 flagged by HRSP_WK2\n",
      "     INC_RANK flagged by INC__ANK\n",
      "     INC_RNKM flagged by INC__NKM\n",
      "     INTRDVB flagged by INTRDVB_\n",
      "     INTRDVBX flagged by INTR_VBX\n",
      "     INTRDVX flagged by INTRDVX_\n",
      "     INTRDVXM flagged by INTR_VXM\n",
      "     JFS_AMT flagged by JFS_AMT_\n",
      "     JFS_AMTM flagged by JFS__MTM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     JGRCFDMV flagged by JGRC_DMV\n",
      "     JGRCFDWK flagged by JGRC_DWK\n",
      "     JGROCYMV flagged by JGRO_YMV\n",
      "     JGROCYWK flagged by JGRO_YWK\n",
      "     LUMPB flagged by LUMPB_\n",
      "     LUMPBX flagged by LUMPBX_\n",
      "     LUMPX flagged by LUMPX_\n",
      "     MARITAL1 flagged by MARI_AL1\n",
      "     NETRENTB flagged by NETR_NTB\n",
      "     NETRENTM flagged by NETR_NTM\n",
      "     NETRENTX flagged by NETR_NTX\n",
      "     NETRNTBX flagged by NETR_TBX\n",
      "     NO_EARNR flagged by NO_E_RNR\n",
      "     OCCEXPNX flagged by OCCE_PNX\n",
      "     OCCULIS1 flagged by OCCU_IS1\n",
      "     OCCULIS2 flagged by OCCU_IS2\n",
      "     OTHINB flagged by OTHINB_\n",
      "     OTHINBX flagged by OTHINBX_\n",
      "     OTHINX flagged by OTHINX_\n",
      "     OTHINXM flagged by OTHINXM_\n",
      "     OTHRECX flagged by OTHRECX_\n",
      "     OTHREGB flagged by OTHREGB_\n",
      "     OTHREGBX flagged by OTHR_GBX\n",
      "     OTHREGX flagged by OTHREGX_\n",
      "     OTHREGXM flagged by OTHR_GXM\n",
      "     PERSLT18 flagged by PERS_T18\n",
      "     PERSOT64 flagged by PERS_T64\n",
      "     RACE2 flagged by RACE2_\n",
      "     REC_FS flagged by REC_FS_\n",
      "     REF_RACE flagged by REF__ACE\n",
      "     RETSRVBX flagged by RETS_VBX\n",
      "     RETSURVB flagged by RETS_RVB\n",
      "     RETSURVM flagged by RETS_RVM\n",
      "     RETSURVX flagged by RETS_RVX\n",
      "     ROYESTB flagged by ROYESTB_\n",
      "     ROYESTBX flagged by ROYE_TBX\n",
      "     ROYESTX flagged by ROYESTX_\n",
      "     ROYESTXM flagged by ROYE_TXM\n",
      "     SEX_REF flagged by SEX_REF_\n",
      "     SEX2 flagged by SEX2_\n",
      "     TYPOWND flagged by TYPOWND_\n",
      "     VEHQ flagged by VEHQ_\n",
      "     WEEKI flagged by WEEKI_\n",
      "     WELFRB flagged by WELFRB_\n",
      "     WELFRBX flagged by WELFRBX_\n",
      "     WELFRX flagged by WELFRX_\n",
      "     WELFRXM flagged by WELFRXM_\n",
      "     WHYNWRK1 flagged by WHYN_RK1\n",
      "     WHYNWRK2 flagged by WHYN_RK2\n",
      "     WK_WRKD1 flagged by WK_W_KD1\n",
      "     WK_WRKD2 flagged by WK_W_KD2\n",
      "dropping flag gields 99\n",
      "Writing to 2018 blockgroupspending file\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "The US Bureau of Labor Statistics publishes the Pubmic Use Microdata (PUMD) to support\n",
    "deeper analysis of its Consumer Expenditure Survey. This module provides functions for \n",
    "downloading PUMD data and its metadata. It also applies business rules for interpreting\n",
    "this dataset.\n",
    "    \n",
    "    oe_bls_cex_pumd_download          - retrieves the PUMD files from the BLS to a new folder\n",
    "    oe_bls_cex_pumd_open_files        - opens the downloaded files into python dataframes\n",
    "    oe_bls_cex_pumd_interpret_meta    - selects a request year of the Variable Dictionary and Historical Grouping\n",
    "    oe_bls_cex_pumd_interpret_data    - applies rule to combine the FMLI, FMLD, MTBI and EXPD files\n",
    "        oe_bls_cex_pumd_flags         - applies flag column rules to fmli, fmld\n",
    "        oe_bls_cex_pumd_select        - For fmli & fmld, this selects demog, geog and expenditure cols of interest\n",
    "    oe_bls_cex_pumd_write             - stores the resulting data structures to pcikle files\n",
    "\n",
    "The final section of this files demonstrates these functions for working examples.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def oe_bls_cex_pumd_download(years, pumddir = './pumd/', cexurl='https://www.bls.gov/cex/'):\n",
    "    \"\"\"\n",
    "    This function downloads the files, dictionaries and hierarchical groupings of in\n",
    "    Bureau of Labor Statistics (BLS), Consumer Expenditure Survey's (CEX) Public Use \n",
    "    Microsample Data (PUMD).\n",
    "        \n",
    "    :param  years:    a list of 4 digit years that are strings like ['2018','2019','2020'] \n",
    "    :param  pumddir:  a string with the path destination of the download & unzipped files \n",
    "    :param  cexurl:   the root URL for the Consumer Expenditure Survey\n",
    "\n",
    "    :return None   The function either succeeds or fails\n",
    "    \"\"\"\n",
    "    \n",
    "    # Avoid conflicts with any previously downloaded\n",
    "    if os.path.exists(pumddir):\n",
    "        print(\"Destination directory '\"+pumddir+\"already exists.\")\n",
    "        print(\"Please remove it or select a new destination directory.\")\n",
    "        raise\n",
    "    else:\n",
    "        os.mkdir(pumddir)\n",
    "\n",
    "    # Download and reformat the HGs as a dictionary of dataframes\n",
    "    for yr in years:\n",
    "        for fn in ('diary','intrvw'):\n",
    "            # download\n",
    "            print('Downloading',yr,fn)\n",
    "            wget.download(cexurl+'pumd/data/comma/'+fn+yr[2:]+'.zip',\n",
    "                          out=pumddir,\n",
    "                          bar=None)\n",
    "            # unzip\n",
    "            with zipfile.ZipFile(pumddir+fn+yr[2:]+'.zip', 'r') as zip_ref:\n",
    "                zip_ref.extractall(pumddir)\n",
    "            \n",
    "    # also need the HG file.  It is a zip of all years.\n",
    "    print('Downloading Hierarchical Grouping file')\n",
    "    wget.download(cexurl+'pumd/stubs.zip', \n",
    "                  out=pumddir,\n",
    "                  bar=None)\n",
    "    with zipfile.ZipFile(pumddir+'stubs.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(pumddir)\n",
    "\n",
    "    # Get the PUMD dictionary\n",
    "    print('Getting the PUMD dictionary')\n",
    "    wget.download(cexurl+'pumd/ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                  out=pumddir,\n",
    "                  bar=None)\n",
    "\n",
    "    return None\n",
    "\n",
    "def oe_bls_cex_pumd_open_files(years, pumddir = './pumd/'):\n",
    "    \"\"\"\n",
    "    This function reads the PUMD data files of the dataset into python data structures. \n",
    "\n",
    "        \n",
    "    :param  years: a list of 4 digit years that are strings     ['2018','2019','2020'] \n",
    "    :param  UCCs: a list of UCCs, six digit as strings     ['123456','234567','345678']\n",
    "\n",
    "    pumdfiles: a dictionary, by year, with the file based dataframes\n",
    "    hg: the Hierarchical Grouping table with linenum, level, title, survey, factor.\n",
    "    vardict: provides a dictionary of the variables (not UCCs) in the PUMD\n",
    "    codedict: provides a table with a description for each coded value in the PUMD\n",
    "\n",
    "    :return  pumdfiles, hg, vardict, codedict\n",
    "    \"\"\"\n",
    "    \n",
    "    filetypes = ['dtbd','dtid','expd','fmld','memd','fmli','itbi','itii','memi','mtbi','ntax']\n",
    "\n",
    "    filereads = {}\n",
    "    for t in filetypes:\n",
    "        filereads[t] = []\n",
    "        \n",
    "    pumd = {}\n",
    "    \n",
    "    for yr in years:\n",
    "        pumd[yr] = {}\n",
    "        for fn in ('diary','intrvw'):\n",
    "            print(\"Reading\",yr,fn)\n",
    "            # Sometimes the intrv folder is in another subdir:  intrvw17/intrvw17/*.csv eg \n",
    "            if ((fn == 'intrvw') & (os.path.exists(pumddir+fn+yr[-2:]+ \"\\\\\"+fn+yr[-2:]+\"\\\\\"))):\n",
    "                folder = fn+yr[-2:]+ \"\\\\\"+fn+yr[-2:]+\"\\\\\"\n",
    "            else:\n",
    "                folder = fn+yr[-2:]+ \"\\\\\"\n",
    "            for f in os.listdir(pumddir+folder):\n",
    "                ftype = f[0:4]\n",
    "                if ftype in filetypes:\n",
    "                    fdf = pd.read_csv(pumddir+folder+f, dtype=object)\n",
    "                    fdf.columns = [c.upper() for c in fdf.columns]\n",
    "                    fdf[\"filename\"] = f\n",
    "                    fdf[\"year\"] = yr\n",
    "                    filereads[ftype].append(fdf)\n",
    "\n",
    "        for t in filetypes:\n",
    "            pumd[yr][t] = pd.concat(filereads[t])   \n",
    "    \n",
    "    print('Reading the Hierarchical Groupings')\n",
    "    # I'll use the Integrated HG.  Its mostly a superset of Interview & Diary HG less a dozen each\n",
    "    hg = {}\n",
    "    hgdtypes = {\"linenum\":int, \"level\":str, \"title\":str, \"ucc\":str, \"survey\":str, \"factor\":str, \"group\":str}\n",
    "    for yr in years:\n",
    "        h = pd.read_fwf(pumddir+'stubs\\\\CE-HG-Integ-'+yr+'.txt', index_col=False,\n",
    "        names = [\"linenum\", \"level\",  \"title\",  \"ucc\",     \"survey\",  \"factor\", \"group\"],\n",
    "        colspecs = [(0, 3),  (3, 6),  (6, 69),  (69, 75),  (82, 85),  (85, 88), (88,95)],\n",
    "        dtype=hgdtypes)    \n",
    "        # Rows with linenum == 2 are just title text that wrapped from the previous row.\n",
    "        for i,r in h.iterrows():\n",
    "            if r.linenum == 2:\n",
    "                h.at[i-1,'title'] = h.at[i-1,'title']+' '+r.title\n",
    "        hg[yr] = h[h.linenum == 1]\n",
    "     \n",
    "    print('Reading the Dictionary')\n",
    "    # The sheet names can varyin capitalization and include spaces\n",
    "    xl = pd.ExcelFile(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx')\n",
    "    varsheet =  [c for c in xl.sheet_names if 'vari' in c.lower()][0]\n",
    "    codesheet = [c for c in xl.sheet_names if 'code' in c.lower()][0]\n",
    "\n",
    "    vardict =   pd.read_excel(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                              sheet_name = varsheet)\n",
    "    codedict =  pd.read_excel(pumddir + 'ce_pumd_interview_diary_dictionary.xlsx',\n",
    "                              sheet_name = codesheet)\n",
    "\n",
    "    # filter the vardict sheet to only those where \n",
    "    #     you year of interest is > First Year > First Quart and < Last Year <Last Quarter\n",
    "    \n",
    "    return  pumd, hg, vardict, codedict\n",
    "\n",
    "def oe_bls_cex_pumd_interpret_data(pumd, vardict, year, sumrules):\n",
    "    \"\"\"\n",
    "    This function applies adjustments, logical rules and corrections to this source\n",
    "    are applied by the related oe_bls_cex_pumd_read function.to PUMD data structures. \n",
    "\n",
    "    :param  years: a list of 4 digit years that are strings     ['2018','2019','2020'] \n",
    "    :param  UCCs: a list of UCCs, six digit as strings     ['123456','234567','345678']\n",
    "\n",
    "    pumdfiles: a dictionary, by year, with the file based dataframes\n",
    "    hg: the Hierarchical Grouping table with linenum, level, title, survey, factor.\n",
    "    vardict: provides a dictionary of the variables (not UCCs) in the PUMD\n",
    "    sumrules: a dataframe of each summary variable name, summary level and list of children \n",
    "            columns to sum\n",
    "\n",
    "    The processing logic replicates what the BLS' own SAS (& R) program does!\n",
    "    See:    https://www.bls.gov/cex/pumd-getting-started-guide.htm\n",
    "            https://www.bls.gov/cex/pumd/sas-ucc.zip\n",
    "            https://www.bls.gov/cex/pumd/r-ucc.zip\n",
    "            \n",
    "    This is also helpful \n",
    "            https://www.bls.gov/cex/pumd_doc.htm\n",
    "            https://www.bls.gov/cex/csxintvw.pdf\n",
    "\n",
    "    :return family:  a dataframe keyed by NEWID\n",
    "    :return expend:  a dataframe keyed by CU & UCC \n",
    "    :return pubfile: a join between family, expend \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Processing PUMD for\", year)\n",
    "\n",
    "    # Get family dataframes for Interview and Diary\n",
    "    fmli = pumd[year]['fmli']\n",
    "    fmld = pumd[year]['fmld']\n",
    "    # Get member level dataframes\n",
    "    mtbi = pumd[year]['mtbi']\n",
    "    expd = pumd[year]['expd']\n",
    "\n",
    "    # column name lists\n",
    "    wtrep = [(\"WTREP\"+str(i+1).zfill(2)) for i in range(44)]+[\"FINLWT21\"] ## WTREP01-REPWT444 and FINL\n",
    "    repwt = [(\"REPWT\"+str(i+1)) for i in range(45)]  # REPWT1-REPWT45\n",
    "    rcost = [(\"RCOST\"+str(i+1)) for i in range(45)]  # RCOST1-RCOST45\n",
    "\n",
    "    # Process Family\n",
    "\n",
    "    def mo_scope(row):\n",
    "        if   (row[\"QINTRVMO\"] in ['01','02','03']) & (row[\"QINTRVYR\"]==year):\n",
    "            return (int(row[\"QINTRVMO\"]) - 1)\n",
    "        elif (row[\"QINTRVMO\"] in ['01','02','03']) & (row[\"QINTRVYR\"]==str(int(year)+1)):\n",
    "            return (4 - int(row[\"QINTRVMO\"]))\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    fmli['mo_scope'] = fmli.apply(mo_scope, axis=1)\n",
    "    fmli[\"source\"] = 'I'\n",
    "    for i in range(45):\n",
    "        fmli[wtrep[i]] = fmli[wtrep[i]].replace('.',np.nan)\n",
    "        fmli[wtrep[i]] = fmli[wtrep[i]].astype(float).fillna(0)\n",
    "        fmli[repwt[i]] = (fmli[wtrep[i]] * fmli[\"mo_scope\"]) / 12\n",
    "\n",
    "    fmld[\"source\"] = \"D\"\n",
    "    fmld[\"mo_scope\"] = 3\n",
    "    for i in range(45):\n",
    "        fmld[wtrep[i]] = fmld[wtrep[i]].replace('.',np.nan)\n",
    "        fmld[wtrep[i]] = fmld[wtrep[i]].astype(float).fillna(0)    \n",
    "        fmld[repwt[i]] = (fmld[wtrep[i]] * fmld[\"mo_scope\"]) / 12\n",
    "\n",
    "    fmli = fmli.reset_index()\n",
    "    fmld = fmld.reset_index()\n",
    "    \n",
    "    oe_bls_cex_pumd_process_flags(fmli,\"FMLI\",vardict)\n",
    "    oe_bls_cex_pumd_process_flags(fmld,\"FMLD\",vardict)\n",
    "\n",
    "    fmlcols = ([c for c in fmli.columns if c in fmld.columns]) # 272 columns\n",
    "    family = pd.concat([fmli[fmlcols],fmld[fmlcols]], axis=0)\n",
    "    \n",
    "    \n",
    "    # Process Expend\n",
    "\n",
    "    mtbi[\"source\"] = \"I\"\n",
    "    mtbi = mtbi[(mtbi[\"REF_YR\"] == year) & (mtbi[\"PUBFLAG\"] == \"2\")]\n",
    "\n",
    "    expd[\"source\"] = \"D\"\n",
    "    \n",
    "    expd[\"COST\"] = pd.to_numeric(expd[\"COST\"], errors='coerce')\n",
    "    expd[\"COST\"] = expd[\"COST\"].astype(float).fillna(0) * 13\n",
    "    expd = expd[expd[\"PUB_FLAG\"] == \"2\"]\n",
    "\n",
    "    expcols =['NEWID','source','UCC','COST'] #,'REF_YR'\n",
    "    expend = pd.concat([mtbi[expcols],expd[expcols]], axis=0)\n",
    "\n",
    "    pubfile = pd.merge(family, expend, on='NEWID', how='inner')\n",
    "    pubfile[\"COST\"] = pubfile[\"COST\"].astype(float).fillna(0)\n",
    "    for i in range(45):\n",
    "        pubfile[rcost[i]] = pubfile[wtrep[i]] * pubfile[\"COST\"]\n",
    "        \n",
    "    #\n",
    "    # TBD: summarize the pubfile, and apply the sumrules\n",
    "    #\n",
    "    \n",
    "    # 1. Start with a df that has CUID/NEWID, COST and UCC columns\n",
    "    # 2. Pivot this df so there's a column for each UCC value\n",
    "        # costs = df.pivot(index='NEWID', columns='UCC', values='COST')\n",
    "    # 3. Ensure that all the expected UCC columns are present\n",
    "    #   # for all the UCC variables, if the cost df is missing that var, costs[missingUCC] = 0\n",
    "    # 4. March from the lowest level upward\n",
    "        # for level in [9,8,7,6,5,4,3,2]:\n",
    "    #   costs[sumvar] = costs[sumrulescolumns].sum(axis=1)\n",
    "        \n",
    "    return pubfile, family, expend, fmli, fmld, mtbi, expd\n",
    "\n",
    "\n",
    "def oe_bls_cex_pumd_flag_NAs(row,flagged,flagcol):\n",
    "    \"\"\"\n",
    "    Process flag fields ensuring A,B,C are NAs\n",
    "    Called by the oe_bls_cex_pumd_process_flags\n",
    "    Initially this is a simple rule, but this function provides a placeholder\n",
    "    for more complex use of the PUMD Variable Dictionary \n",
    "    \"\"\"\n",
    "    if row[flagcol] in [\"A\",\"B\",\"C\"]:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return row[flagged]\n",
    "    return None\n",
    "\n",
    "\n",
    "def oe_bls_cex_pumd_process_flags(df,filename,vd):\n",
    "    \"\"\"\n",
    "    PUMD variables may be accompanied by a sister flag column that indicates\n",
    "    how missing and top/bottom coded values should be handled.\n",
    "    This function applies flag rules to a dataframe then drops the flag columns.\n",
    "    \"\"\"\n",
    "    print(\"Processing flags for\",filename)\n",
    "    flags = {}\n",
    "    flag_candidates = vd[[\"Variable Name\",\"Flag name\"]][~vd[\"Flag name\"].isna()][vd[\"File\"] == filename].drop_duplicates()\n",
    "    for i,r in flag_candidates.iterrows():\n",
    "        if (r[\"Variable Name\"] in df.columns) & (r[\"Flag name\"] in df.columns):\n",
    "            flags[r[\"Variable Name\"]] = r[\"Flag name\"]\n",
    "    for col in flags.keys():\n",
    "        print(\"    \",col,\"flagged by\",flags[col])\n",
    "        df[col[:-1]] = df.apply(lambda row: oe_bls_cex_pumd_flag_NAs(row,col,flags[col]), axis=1)\n",
    "    df.drop([c for c in flags.values()], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def oe_bls_cex_pumd_interpret_meta(hg,vd,cd,year):\n",
    "\n",
    "    print(\"Narrowing metadata to\", year)\n",
    "    \n",
    "    # Interpret the Hierarchical Grouping\n",
    "    h = hg[year]\n",
    "    \n",
    "    # Generate the summarization rules from HG\n",
    "    h[\"level\"] = h[\"level\"].astype(int)\n",
    "    sumdict = {}\n",
    "    sumrules = {}\n",
    "    for level in [9,8,7,6,5,4,3,2]:\n",
    "        for i,g in h[h.level.isin([level, level-1])].iterrows():        \n",
    "            if g.level == level-1:\n",
    "                rule = g.ucc\n",
    "                sumdict[rule] = level-1\n",
    "                sumrules[rule] = []\n",
    "            else:\n",
    "                sumrules[rule].append(g.ucc)\n",
    "\n",
    "    emptyrules = [r for r in sumrules.keys() if len(sumrules[r]) == 0]\n",
    "    for rule in emptyrules:\n",
    "        sumrules.pop(rule)\n",
    "        sumdict.pop(rule)\n",
    "\n",
    "    # Test the rules\n",
    "    for rule in sumrules.keys():\n",
    "        if (len(sumrules[rule]) > 0) & (rule.isnumeric()):\n",
    "            print('invalid rule',rule,': members but numeric')\n",
    "        if (len(sumrules[rule]) == 0) & (not rule.isnumeric()):\n",
    "            print('invalid rule',rule,': no members but not numeric')\n",
    "    # the rule level is needed so they can be applied bottom up\n",
    "    r = pd.DataFrame.from_dict({'name':  list(sumdict.keys()),\n",
    "                                'level': [sumdict[r] for r in sumdict.keys()],\n",
    "                                'rule':  [sumrules[r] for r in sumdict.keys()]})    \n",
    "    \n",
    "    # Interpret the Var Dictionary\n",
    "    vd[\"Last year\"] = vd[\"Last year\"].fillna(datetime.now().year)\n",
    "    v = vd[(int(year) >= vd[\"First year\"] ) & (int(year) <= vd[\"Last year\"] )]\n",
    "    \n",
    "    # Interpret the Code Dictionary\n",
    "    cd[\"Last year\"] = cd[\"Last year\"].fillna(datetime.now().year)\n",
    "    c = cd[(int(year) >= cd[\"First year\"] ) & (int(year) <= cd[\"Last year\"] )]\n",
    "    \n",
    "    return h,r,v,c\n",
    "\n",
    "\n",
    "def oe_bls_cex_pumd_write(df, year):\n",
    "    \"\"\"\n",
    "    This function writes a final dataframe to file.\n",
    "    \"\"\"\n",
    "    print(\"Writing to \"+year+\" blockgroupspending file\")\n",
    "    df.to_csv(year+'blockgroupspending.csv', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Capitalized variables are globals or multi-year storage\n",
    "    # Lowercase variables are those for a given working year\n",
    "    \n",
    "    CEXURL = 'https://www.bls.gov/cex/'\n",
    "    PUMDDIR = \"D:\\\\Open Environments\\\\data\\\\bls\\\\cex\\\\pumd\\\\\"\n",
    "    YEARS = ['2018'] #['2016','2017','2018','2019','2020']\n",
    "    \n",
    "    oe_bls_cex_pumd_download(YEARS, pumddir = PUMDDIR, cexurl=CEXURL)\n",
    "    \n",
    "    PUMD, HG, VARDICT, CODEDICT = oe_bls_cex_pumd_open_files(YEARS, pumddir = PUMDDIR)\n",
    "    \n",
    "    for yr in YEARS: \n",
    "        hg, sumrules, vardict, codedict    = oe_bls_cex_pumd_interpret_meta(HG,VARDICT,CODEDICT,yr)\n",
    "        pubfile, family, expend, fmli, fmld, mtbi, expd  = \\\n",
    "            oe_bls_cex_pumd_interpret_data(PUMD,VARDICT,yr,sumrules)\n",
    "        oe_bls_cex_pumd_write(family,yr)\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d7c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b2cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03927d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
